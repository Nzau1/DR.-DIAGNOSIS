{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1XbJG07C5M0hd7iTtglZ2PE2U5k_g_QXc",
      "authorship_tag": "ABX9TyPvIt+shSStzv0hW4JK6UwV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nzau1/DR.-DIAGNOSIS/blob/main/disease_diagnosis_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY77gKMGHv8y",
        "outputId": "bacd0c3c-bbe5-4558-bd87-e7d8ff0126af"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.2995 - loss: 3.6624 - val_accuracy: 0.7762 - val_loss: 0.7491\n",
            "Epoch 2/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.5980 - loss: 1.4777 - val_accuracy: 0.8124 - val_loss: 0.5891\n",
            "Epoch 3/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.6378 - loss: 1.3023 - val_accuracy: 0.8234 - val_loss: 0.5314\n",
            "Epoch 4/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.6595 - loss: 1.2170 - val_accuracy: 0.8219 - val_loss: 0.5096\n",
            "Epoch 5/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 1.1694 - val_accuracy: 0.8324 - val_loss: 0.4948\n",
            "Epoch 6/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.6811 - loss: 1.1253 - val_accuracy: 0.8350 - val_loss: 0.4764\n",
            "Epoch 7/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.6863 - loss: 1.1039 - val_accuracy: 0.8361 - val_loss: 0.4690\n",
            "Epoch 8/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - accuracy: 0.6918 - loss: 1.0859 - val_accuracy: 0.8372 - val_loss: 0.4680\n",
            "Epoch 9/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.6974 - loss: 1.0644 - val_accuracy: 0.8406 - val_loss: 0.4544\n",
            "Epoch 10/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7010 - loss: 1.0489 - val_accuracy: 0.8382 - val_loss: 0.4540\n",
            "Epoch 11/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.7032 - loss: 1.0331 - val_accuracy: 0.8378 - val_loss: 0.4525\n",
            "Epoch 12/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 1.0203 - val_accuracy: 0.8427 - val_loss: 0.4433\n",
            "Epoch 13/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 1.0095 - val_accuracy: 0.8424 - val_loss: 0.4417\n",
            "Epoch 14/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.7111 - loss: 1.0041 - val_accuracy: 0.8417 - val_loss: 0.4414\n",
            "Epoch 15/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.9931 - val_accuracy: 0.8405 - val_loss: 0.4410\n",
            "Epoch 16/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7150 - loss: 0.9884 - val_accuracy: 0.8442 - val_loss: 0.4386\n",
            "Epoch 17/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 0.9761 - val_accuracy: 0.8431 - val_loss: 0.4383\n",
            "Epoch 18/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7189 - loss: 0.9739 - val_accuracy: 0.8427 - val_loss: 0.4327\n",
            "Epoch 19/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7217 - loss: 0.9665 - val_accuracy: 0.8437 - val_loss: 0.4299\n",
            "Epoch 20/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7240 - loss: 0.9615 - val_accuracy: 0.8432 - val_loss: 0.4304\n",
            "Epoch 21/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.9538 - val_accuracy: 0.8459 - val_loss: 0.4244\n",
            "Epoch 22/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.9412 - val_accuracy: 0.8432 - val_loss: 0.4279\n",
            "Epoch 23/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 0.9389 - val_accuracy: 0.8418 - val_loss: 0.4273\n",
            "Epoch 24/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.7284 - loss: 0.9473 - val_accuracy: 0.8471 - val_loss: 0.4214\n",
            "Epoch 25/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.9382 - val_accuracy: 0.8458 - val_loss: 0.4204\n",
            "Epoch 26/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.9247 - val_accuracy: 0.8463 - val_loss: 0.4226\n",
            "Epoch 27/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.9284 - val_accuracy: 0.8460 - val_loss: 0.4196\n",
            "Epoch 28/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.9269 - val_accuracy: 0.8459 - val_loss: 0.4214\n",
            "Epoch 29/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.9154 - val_accuracy: 0.8465 - val_loss: 0.4192\n",
            "Epoch 30/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.9148 - val_accuracy: 0.8464 - val_loss: 0.4197\n",
            "Epoch 31/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.9209 - val_accuracy: 0.8458 - val_loss: 0.4149\n",
            "Epoch 32/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.9070 - val_accuracy: 0.8462 - val_loss: 0.4146\n",
            "Epoch 33/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.9124 - val_accuracy: 0.8461 - val_loss: 0.4185\n",
            "Epoch 34/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 0.9142 - val_accuracy: 0.8472 - val_loss: 0.4135\n",
            "Epoch 35/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.9020 - val_accuracy: 0.8476 - val_loss: 0.4168\n",
            "Epoch 36/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.9017 - val_accuracy: 0.8469 - val_loss: 0.4143\n",
            "Epoch 37/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.9004 - val_accuracy: 0.8491 - val_loss: 0.4090\n",
            "Epoch 38/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.8976 - val_accuracy: 0.8483 - val_loss: 0.4116\n",
            "Epoch 39/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7410 - loss: 0.8977 - val_accuracy: 0.8481 - val_loss: 0.4100\n",
            "Epoch 40/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - accuracy: 0.7418 - loss: 0.8892 - val_accuracy: 0.8479 - val_loss: 0.4097\n",
            "Epoch 41/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 0.8917 - val_accuracy: 0.8458 - val_loss: 0.4119\n",
            "Epoch 42/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.8882 - val_accuracy: 0.8464 - val_loss: 0.4177\n",
            "Epoch 43/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.8990 - val_accuracy: 0.8494 - val_loss: 0.4059\n",
            "Epoch 44/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 0.8956 - val_accuracy: 0.8481 - val_loss: 0.4093\n",
            "Epoch 45/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.8914 - val_accuracy: 0.8484 - val_loss: 0.4077\n",
            "Epoch 46/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.8887 - val_accuracy: 0.8463 - val_loss: 0.4116\n",
            "Epoch 47/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.8906 - val_accuracy: 0.8480 - val_loss: 0.4133\n",
            "Epoch 48/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.8886 - val_accuracy: 0.8481 - val_loss: 0.4101\n",
            "Epoch 49/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.8852 - val_accuracy: 0.8463 - val_loss: 0.4123\n",
            "Epoch 50/50\n",
            "\u001b[1m6174/6174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.8785 - val_accuracy: 0.8481 - val_loss: 0.4114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Model saved to /content/drive/MyDrive/diagnosis/disease_dnn_model.h5!\n",
            "\u001b[1m1544/1544\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.4070\n",
            "\n",
            "ğŸ” Test Accuracy: 84.81%\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define file paths\n",
        "data_folder = \"/content/drive/MyDrive/diagnosis/processed_data\"\n",
        "X_train_path = f\"{data_folder}/X_train.csv\"\n",
        "X_test_path = f\"{data_folder}/X_test.csv\"\n",
        "y_train_path = f\"{data_folder}/y_train.csv\"\n",
        "y_test_path = f\"{data_folder}/y_test.csv\"\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = pd.read_csv(X_train_path)\n",
        "X_test = pd.read_csv(X_test_path)\n",
        "y_train = pd.read_csv(y_train_path)\n",
        "y_test = pd.read_csv(y_test_path)\n",
        "\n",
        "# Encode target labels (if not already encoded)\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train.values.ravel())  # Fit on training data\n",
        "\n",
        "# Ensure test labels are only those seen during training\n",
        "y_test = y_test.values.ravel()\n",
        "y_test = np.array([label_encoder.transform([label])[0] if label in label_encoder.classes_ else -1 for label in y_test])\n",
        "\n",
        "# Remove invalid test samples\n",
        "valid_indices = y_test != -1\n",
        "X_test = X_test[valid_indices]\n",
        "y_test = y_test[valid_indices]\n",
        "\n",
        "# Convert to TensorFlow format\n",
        "X_train, X_test = np.array(X_train), np.array(X_test)\n",
        "\n",
        "# Define model architecture\n",
        "def create_model(learning_rate=0.001, dropout_rate=0.3):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(dropout_rate),\n",
        "\n",
        "        Dense(len(np.unique(y_train)), activation='softmax')  # Multi-class classification\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "best_lr = 0.001  # Default learning rate\n",
        "best_dropout = 0.3  # Default dropout\n",
        "\n",
        "# Train model\n",
        "model = create_model(learning_rate=best_lr, dropout_rate=best_dropout)\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Save model to Google Drive\n",
        "model_path = \"/content/drive/MyDrive/diagnosis/disease_dnn_model.h5\"\n",
        "model.save(model_path)\n",
        "print(f\"\\nâœ… Model saved to {model_path}!\")\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nğŸ” Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ]
    }
  ]
}